{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs541 final project",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIfi3nzxuSch"
      },
      "source": [
        "!pip install -q -U tensorflow>=1.8.0\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnjohQg3wPDn",
        "outputId": "95c00d65-1881-49db-bcd4-3eed9440a495"
      },
      "source": [
        "# Load the fashion-mnist pre-shuffled train data and test data\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
        "\n",
        "# normalize\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# Further break training data into train / validation sets (# put 5000 into validation set and keep remaining 55,000 for train)\n",
        "(x_train, x_valid) = x_train[5000:], x_train[:5000] \n",
        "(y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
        "\n",
        "# Reshape input data from (28, 28) to (28, 28, 1)\n",
        "w, h = 28, 28\n",
        "x_train = x_train.reshape(x_train.shape[0], w, h, 1)\n",
        "x_valid = x_valid.reshape(x_valid.shape[0], w, h, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], w, h, 1)\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_valid = tf.keras.utils.to_categorical(y_valid, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Print training set shape\n",
        "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
        "\n",
        "# Print the number of training, validation, and test datasets\n",
        "print(x_train.shape[0], 'train set')\n",
        "print(x_valid.shape[0], 'validation set')\n",
        "print(x_test.shape[0], 'test set')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n",
            "x_train shape: (55000, 28, 28, 1) y_train shape: (55000, 10)\n",
            "55000 train set\n",
            "5000 validation set\n",
            "10000 test set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTdXKCjtszo8",
        "outputId": "ad06a100-9c43-4d69-9f09-512a73c7c5ff"
      },
      "source": [
        "#clean this up\n",
        "#add in dropout\n",
        "#add in representation size and layers\n",
        "\"\"\"\n",
        "Returns a TensorFlow layer based on layer information stored in tuple.\n",
        "(convolution, nfilters, filter-size, stride)\n",
        "(pooling, pool_size, stride)\n",
        "(dense, nnodes)\n",
        "(softmax, nnodes)\n",
        "\"\"\"\n",
        "def create_layer(layer, input_shape):\n",
        "  layer_type = layer[0]\n",
        "  if input_shape != None:\n",
        "    if layer_type == 'convolution':\n",
        "      return tf.keras.layers.Conv2D(filters=layer[1], kernel_size=layer[2], strides=layer[3], padding='same', input_shape = input_shape)\n",
        "    if layer_type == 'pooling':\n",
        "      return tf.keras.layers.MaxPooling2D(pool_size=layer[1], strides=layer[2], input_shape = input_shape)\n",
        "    if layer_type == 'dense':\n",
        "      return tf.keras.layers.Dense(layer[1], input_shape = input_shape)\n",
        "    if layer_type == 'softmax':\n",
        "      return tf.keras.layers.Dense(layer[1], activation='softmax', input_shape = input_shape)\n",
        "  else:\n",
        "    if layer_type == 'convolution':\n",
        "      return tf.keras.layers.Conv2D(filters=layer[1], kernel_size=layer[2], strides=layer[3], padding='same')\n",
        "    if layer_type == 'pooling':\n",
        "      return tf.keras.layers.MaxPooling2D(pool_size=layer[1], strides=layer[2])\n",
        "    if layer_type == 'dense':\n",
        "      return tf.keras.layers.Dense(layer[1], activation='relu')\n",
        "    if layer_type == 'softmax':\n",
        "      return tf.keras.layers.Dense(layer[1], activation='softmax')\n",
        "#need to add global average pooling?\n",
        "\n",
        "\"\"\"\n",
        "Returns a TensorFlow architecture based on architecture information stored as a list of tuples and input shape.\n",
        "\"\"\"\n",
        "def create_architecture(layers, input_shape):\n",
        "  model = tf.keras.Sequential()\n",
        "  for i in range(len(layers)):\n",
        "    if i == 0: layer = create_layer(layers[i], input_shape)\n",
        "    else: \n",
        "      if (layers[i][0] == 'dense' or layers[i][0] == 'softmax') and (layers[i-1][0] == 'convolution' or layers[i-1][0] == 'pooling'):\n",
        "        model.add(tf.keras.layers.Flatten()) # flatten if this layer is dense and previous layer was 2D\n",
        "      layer = create_layer(layers[i], None)\n",
        "    model.add(layer)\n",
        "  return model\n",
        "\n",
        "layer1 = ('convolution', 64, 2, 1)\n",
        "layer2 = ('pooling', 2, 2)\n",
        "layer3 = ('convolution', 64, 2, 1)\n",
        "layer4 = ('pooling', 2, 2)\n",
        "layer5 = ('dense', 256)\n",
        "layer6 = ('softmax', 10)\n",
        "\n",
        "layers = [layer1, layer2, layer3, layer4, layer5, layer6]\n",
        "model = create_architecture(layers, (28, 28, 1))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_19 (Conv2D)           (None, 28, 28, 64)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 14, 14, 64)        16448     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 256)               803072    \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 822,410\n",
            "Trainable params: 822,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EX8fgRiyyvsG"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ikYHr5DyxAR",
        "outputId": "5c1bc5de-dd98-45f3-f55c-b7f166bd75aa"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose = 1, save_best_only=True)\n",
        "model.fit(x_train,\n",
        "         y_train,\n",
        "         batch_size=64,\n",
        "         epochs=1,\n",
        "         validation_data=(x_valid, y_valid),\n",
        "         callbacks=[checkpointer])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "860/860 [==============================] - 71s 82ms/step - loss: 0.5784 - accuracy: 0.7922 - val_loss: 0.3069 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.30687, saving model to model.weights.best.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f19264bbb90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJA1Hncgy5bf",
        "outputId": "e543d56b-8500-4246-b59b-9f7ba08e1c81"
      },
      "source": [
        "# Load the weights with the best validation accuracy\n",
        "model.load_weights('model.weights.best.hdf5')\n",
        "\n",
        "# Evaluate the model on test set\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Print test accuracy\n",
        "print('\\n', 'Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Test accuracy: 0.8794000148773193\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}